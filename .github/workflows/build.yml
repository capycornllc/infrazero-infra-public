name: build

on:
  workflow_dispatch:

jobs:
  build:
    runs-on: ubuntu-latest
    env:
      AWS_ACCESS_KEY_ID: ${{ secrets.s3_access_key_id }}
      AWS_SECRET_ACCESS_KEY: ${{ secrets.s3_secret_access_key }}
      AWS_DEFAULT_REGION: ${{ secrets.s3_region }}
      S3_REGION: ${{ secrets.s3_region }}
      CLOUD_REGION: ${{ secrets.cloud_region }}
      PROJECT_SLUG: ${{ secrets.project_slug }}
      ENVIRONMENT: ${{ secrets.env }}
      S3_ENDPOINT: ${{ secrets.s3_endpoint }}
      INFRA_STATE_BUCKET: ${{ secrets.infra_state_bucket }}
      OPS_SSH_KEYS_JSON: ${{ secrets.OPS_SSH_KEYS_JSON }}
      DEBUG_ROOT_PASSWORD: ${{ secrets.DEBUG_ROOT_PASSWORD }}
      S3_ACCESS_KEY_ID: ${{ secrets.s3_access_key_id }}
      S3_SECRET_ACCESS_KEY: ${{ secrets.s3_secret_access_key }}
      DB_BACKUP_BUCKET: ${{ secrets.db_backup_bucket }}
      DATABASES_JSON: ${{ secrets.databases_json }}
      INFISICAL_DB_BACKUP_AGE_PUBLIC_KEY: ${{ secrets.infisical_db_backup_age_public_key }}
      INFISICAL_DB_BACKUP_AGE_PRIVATE_KEY: ${{ secrets.infisical_db_backup_age_private_key }}
      DB_TYPE: ${{ secrets.db_type }}
      DB_VERSION: ${{ secrets.db_version }}
      INFISICAL_PASSWORD: ${{ secrets.infisical_password }}
      INFISICAL_EMAIL: ${{ secrets.infisical_email }}
      INFISICAL_ORGANIZATION: ${{ secrets.infisical_organization }}
      INFISICAL_NAME: ${{ secrets.infisical_name }}
      INFISICAL_SURNAME: ${{ secrets.infisical_surname }}
      INFISICAL_POSTGRES_DB: ${{ secrets.infisical_postgres_db }}
      INFISICAL_POSTGRES_USER: ${{ secrets.infisical_postgres_user }}
      INFISICAL_POSTGRES_PASSWORD: ${{ secrets.infisical_postgres_password }}
      INFISICAL_ENCRYPTION_KEY: ${{ secrets.infisical_encryption_key }}
      INFISICAL_AUTH_SECRET: ${{ secrets.infisical_auth_secret }}
      INFISICAL_RESTORE_FROM_S3: ${{ secrets.infisical_restore_from_s3 }}
      INFISICAL_BOOTSTRAP_SECRETS: ${{ secrets.infisical_bootstrap_secrets }}
      INFISICAL_PROJECT_NAME: ${{ secrets.infisical_project_name }}
      BASTION_CLOUD_INIT: ${{ secrets.bastion_cloud_init }}
      EGRESS_CLOUD_INIT: ${{ secrets.egress_cloud_init }}
      DB_CLOUD_INIT: ${{ secrets.db_cloud_init }}
      NODE_PRIMARY_CLOUD_INIT: ${{ secrets.node_primary_cloud_init }}
      NODES_SECONDARY_CLOUD_INIT: ${{ secrets.nodes_secondary_cloud_init }}
      BASTION_FQDN: ${{ secrets.bastion_fqdn }}
      GRAFANA_FQDN: ${{ secrets.grafana_fqdn }}
      LOKI_FQDN: ${{ secrets.loki_fqdn }}
      INFISICAL_FQDN: ${{ secrets.infisical_fqdn }}
      KUBERNETES_FQDN: ${{ secrets.kubernetes_fqdn }}
      DB_FQDN: ${{ secrets.db_fqdn }}
      INTERNAL_SERVICES_DOMAINS_JSON: ${{ secrets.internal_services_domains_json }}
      DEPLOYED_APPS_JSON: ${{ secrets.deployed_apps_json }}
      ADDITIONAL_HOSTNAMES: ${{ secrets.additional_hostnames }}
      GH_TOKEN: ${{ secrets.gh_token }}
      GH_OWNER: ${{ secrets.gh_owner }}
      GH_INFRA_REPO: ${{ secrets.gh_infra_repo }}
      GH_GITOPS_REPO: ${{ secrets.gh_gitops_repo }}
      GHCR_TOKEN: ${{ secrets.ghcr_token }}
      BASTION_SERVER_TYPE: ${{ secrets.bastion_server_type }}
      EGRESS_SERVER_TYPE: ${{ secrets.egress_server_type }}
      DB_SERVER_TYPE: ${{ secrets.db_server_type }}
      K3S_NODE_SERVER_TYPE: ${{ secrets.k3s_node_server_type }}
      K3S_CONTROL_PLANES_COUNT: ${{ secrets.k3s_control_planes_count }}
      K3S_WORKERS_COUNT: ${{ secrets.k3s_workers_count }}
      K3S_JOIN_TOKEN: ${{ secrets.k3s_join_token }}
      LOAD_BALANCER_CONFIG: ${{ secrets.load_balancer_config }}
      ARGOCD_ADMIN_PASSWORD: ${{ secrets.argocd_admin_password }}
      ARGOCD_FQDN: ${{ secrets.argocd_fqdn }}
      CLOUDFLARE_API_TOKEN: ${{ secrets.cloudflare_api_token }}
      WG_SERVER_PRIVATE_KEY: ${{ secrets.wg_server_private_key }}
      WG_SERVER_PUBLIC_KEY: ${{ secrets.wg_server_public_key }}
      WG_SERVER_ADDRESS: ${{ secrets.wg_server_address }}
      WG_LISTEN_PORT: ${{ secrets.wg_listen_port }}
      WG_ADMIN_PEERS_JSON: ${{ secrets.WG_ADMIN_PEERS_JSON }}
      WG_PRESHARED_KEYS_JSON: ${{ secrets.WG_PRESHARED_KEYS_JSON }}
      HCLOUD_TOKEN: ${{ secrets.hetzner_cloud_token }}
      TF_VAR_hcloud_token: ${{ secrets.hetzner_cloud_token }}
    steps:
      - name: Checkout
        uses: actions/checkout@v4

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: "3.11"

      - name: Setup OpenTofu
        uses: opentofu/setup-opentofu@v1

      - name: Install Python deps
        run: |
          python -m pip install --upgrade pip
          pip install pyyaml jsonschema requests

      - name: Read config values
        run: |
          python - <<'PY'
          import os
          import yaml
          from pathlib import Path

          cfg = yaml.safe_load(Path("config/infra.yaml").read_text()) or {}
          bootstrap = cfg.get("bootstrap", {})
          s3_backend = cfg.get("s3_backend", {})
          db_volume = cfg.get("db_volume", {})

          project_slug = (os.getenv("PROJECT_SLUG") or "").strip()
          env_override = (os.getenv("ENVIRONMENT") or "").strip() or (os.getenv("ENV") or "").strip()
          config_env = str(cfg.get("environment", "") or "").strip()
          runtime_env = env_override or config_env

          state_prefix = s3_backend.get("state_prefix", "")
          db_volume_name = db_volume.get("name", "")
          if project_slug and runtime_env:
              state_prefix = f"{project_slug}/{runtime_env}"
              db_volume_name = f"{project_slug}-{runtime_env}-db"

          env_lines = [
              f"BOOTSTRAP_PRESIGN_EXPIRY={bootstrap.get('presign_expiry_seconds', 3600)}",
              f"STATE_PREFIX={state_prefix}",
              f"DB_VOLUME_NAME={db_volume_name}",
          ]
          with open(os.environ["GITHUB_ENV"], "a", encoding="utf-8") as fh:
              fh.write("\n".join(env_lines) + "\n")
          PY


      - name: Normalize S3 endpoint
        run: |
          if [ -z "${S3_ENDPOINT}" ]; then
            echo "S3_ENDPOINT is required" >&2
            exit 1
          fi
          if [[ "${S3_ENDPOINT}" != http://* && "${S3_ENDPOINT}" != https://* ]]; then
            echo "S3_ENDPOINT=https://${S3_ENDPOINT}" >> "$GITHUB_ENV"
          fi


      - name: Normalize S3 region
        run: |
          if [ -z "${S3_REGION}" ]; then
            if [ -z "${CLOUD_REGION}" ]; then
              echo "S3_REGION or CLOUD_REGION is required" >&2
              exit 1
            fi
            echo "S3_REGION=${CLOUD_REGION}" >> "$GITHUB_ENV"
            echo "AWS_DEFAULT_REGION=${CLOUD_REGION}" >> "$GITHUB_ENV"
          else
            echo "AWS_DEFAULT_REGION=${S3_REGION}" >> "$GITHUB_ENV"
          fi


      - name: Display S3 settings
        run: |
          mask() {
            local value="$1"
            local length=${#value}
            if [ $length -le 4 ]; then
              printf '%s' "$value"
              return
            fi
            local prefix=${value:0:2}
            local suffix=${value: -2}
            printf '%s****%s' "$prefix" "$suffix"
          }

          region_display="${S3_REGION:-${CLOUD_REGION:-}}"
          echo "S3_REGION=${region_display}"
          echo "AWS_ACCESS_KEY_ID=$(mask "${AWS_ACCESS_KEY_ID:-}")"
          echo "AWS_SECRET_ACCESS_KEY=$(mask "${AWS_SECRET_ACCESS_KEY:-}")"

      - name: Validate config
        run: python scripts/validate-config.py --config config/infra.yaml --schema config/schema.json

      - name: Package and upload bootstraps
        run: |
          set -euo pipefail
          mkdir -p build/bootstrap
          chmod +x bootstrap/*.sh
          for role in bastion egress node1 nodecp node2 db; do
            extra_files=()
            if [ "$role" = "egress" ]; then
              extra_files+=(infisical-bootstrap.sh)
            fi
            if [ "$role" = "node1" ]; then
              extra_files+=(infisical-admin-secret.sh)
            fi
            tar --zstd -cf "build/bootstrap/${role}.tar.zst" -C bootstrap common.sh "${role}.sh" "${extra_files[@]}"
            sha=$(sha256sum "build/bootstrap/${role}.tar.zst" | awk '{print $1}')
            echo "$sha" > "build/bootstrap/${role}.sha256"

            aws --endpoint-url "$S3_ENDPOINT" s3 cp "build/bootstrap/${role}.tar.zst" "s3://$INFRA_STATE_BUCKET/bootstrap/${role}.tar.zst"
            url=$(aws --endpoint-url "$S3_ENDPOINT" s3 presign "s3://$INFRA_STATE_BUCKET/bootstrap/${role}.tar.zst" --expires-in "$BOOTSTRAP_PRESIGN_EXPIRY")
            echo "$url" > "build/bootstrap/${role}.url"
          done

          manifest='{}'
          for role in bastion egress node1 nodecp node2 db; do
            sha=$(cat "build/bootstrap/${role}.sha256")
            url=$(cat "build/bootstrap/${role}.url")
            manifest=$(jq -c --arg role "$role" --arg url "$url" --arg sha "$sha" '. + {($role): {url: $url, sha256: $sha}}' <<<"$manifest")
          done
          echo "$manifest" | jq '.' > build/bootstrap_artifacts.json

      - name: Render backend + tfvars
        run: |
          python scripts/render-backend.py --config config/infra.yaml --output tofu/backend.hcl
          python scripts/render-config.py --config config/infra.yaml --output tofu/tofu.tfvars.json --bootstrap-artifacts build/bootstrap_artifacts.json

      - name: Init OpenTofu
        run: tofu -chdir=tofu init -no-color -backend-config=backend.hcl

      - name: Destroy stack (keep volume)
        run: |
          chmod +x scripts/*.sh
          pushd tofu
          ../scripts/destroy-without-volume.sh
          popd

      - name: Import DB volume if exists
        run: |
          chmod +x scripts/*.sh
          pushd tofu
          DB_VOLUME_NAME="$DB_VOLUME_NAME" ../scripts/import-volume.sh
          popd

      - name: Import SSH keys if exist
        run: python scripts/import-ssh-keys.py --tofu-dir tofu

      - name: Apply OpenTofu
        run: bash scripts/tofu-retry.sh tofu -chdir=tofu apply -no-color -auto-approve -parallelism=1 -var-file=tofu.tfvars.json

      - name: Sync Cloudflare DNS
        if: ${{ env.CLOUDFLARE_API_TOKEN != '' }}
        run: |
          LB_IP=$(tofu -chdir=tofu output -no-color -raw load_balancer_public_ipv4)
          BASTION_IP=$(tofu -chdir=tofu output -no-color -raw bastion_public_ipv4)
          EGRESS_IP=$(tofu -chdir=tofu output -no-color -raw egress_public_ipv4)
          python scripts/sync-cloudflare-dns.py --config config/infra.yaml --lb-ip "$LB_IP" --bastion-public-ip "$BASTION_IP" --egress-public-ip "$EGRESS_IP"
